import sys
import os
import json
import shutil
import cv2
import numpy as np
import pandas as pd
import torch
from pathlib import Path
from tqdm import tqdm

# --- 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ---
current_file_path = Path(__file__).resolve()
project_root = current_file_path.parent.parent 
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

try:
    from functions.extract_bbox_and_id import extract_bbox_and_id
except ImportError:
    print("âŒ 'functions' ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

try:
    from mmpose.apis import init_model, inference_topdown
    from mmengine import Config
    from mmpose.utils import register_all_modules
    # [ì¶”ê°€] ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì¶œë ¥ í¬ë§·ì„ ë§ì¶”ê¸° ìœ„í•œ í•¨ìˆ˜ë“¤
    from mmpose.structures import merge_data_samples, split_instances
except ImportError:
    print("âŒ MMPose ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# --- 2. ê²½ë¡œ ì„¤ì • ---
data_path = Path("/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data")
base_path = project_root 

df_path = data_path / "metadata.csv"
if not df_path.exists():
    print(f"âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì—†ìŒ: {df_path}")
    sys.exit(1)
    
df = pd.read_csv(df_path)
common_path = df['common_path'][1]

checkpoint_path = data_path / "checkpoints/sapiens/pose/sapiens_0.3b_coco_wholebody_best_coco_wholebody_AP_620.pth"
frame_path = data_path / "1_FRAME" / common_path
sam_path = data_path / "8_SAM" / common_path
output_json_dir = base_path / "test" / "keypoints_result"

# --- 3. Helper: Numpy -> JSON ë³€í™˜ (ìš”ì²­í•˜ì‹  í•¨ìˆ˜) ---
def to_py(obj):
    """numpy ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python ê°ì²´ë¡œ ë³€í™˜"""
    import numpy as _np
    if isinstance(obj, _np.ndarray): 
        return obj.tolist()
    if isinstance(obj, (_np.floating,)): 
        return float(obj)
    if isinstance(obj, (_np.integer,)):  
        return int(obj)
    if isinstance(obj, dict):  
        return {k: to_py(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple)): 
        return [to_py(v) for v in obj]
    return obj

# --- 4. Helper: Padding & Crop ---
def get_padded_crop(image, bbox, padding_ratio=0.2):
    x1, y1, x2, y2 = bbox
    h, w = image.shape[:2]
    
    box_w = x2 - x1
    box_h = y2 - y1
    cx = x1 + box_w / 2
    cy = y1 + box_h / 2
    
    new_w = box_w * (1 + padding_ratio)
    new_h = box_h * (1 + padding_ratio)
    
    new_x1 = int(cx - new_w / 2)
    new_y1 = int(cy - new_h / 2)
    new_x2 = int(cx + new_w / 2)
    new_y2 = int(cy + new_h / 2)
    
    new_x1 = max(0, new_x1)
    new_y1 = max(0, new_y1)
    new_x2 = min(w, new_x2)
    new_y2 = min(h, new_y2)
    
    if new_x2 <= new_x1 or new_y2 <= new_y1:
        return None, None

    crop_img = image[new_y1:new_y2, new_x1:new_x2]
    return crop_img, [new_x1, new_y1, new_x2, new_y2]

# --- 5. Helper: Sapiens Config ìƒì„± (ì˜¤ë¥˜ ìˆ˜ì • ë²„ì „) ---
def get_sapiens_config(ckpt_path):
    image_size = [768, 1024]
    
    # Pipeline ì •ì˜ (inference_topdown í•„ìˆ˜)
    test_pipeline = [
        dict(type='LoadImage'),
        dict(type='GetBBoxCenterScale'),
        dict(type='TopdownAffine', input_size=image_size, use_udp=True),
        dict(type='PackPoseInputs')
    ]

    model_cfg = dict(
        type='TopdownPoseEstimator',
        data_preprocessor=dict(
            type='PoseDataPreprocessor',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            bgr_to_rgb=True
        ),
        backbone=dict(
            type='mmpretrain.VisionTransformer',
            arch=dict(
                embed_dims=1024, num_layers=24, num_heads=16, feedforward_channels=4096
            ),
            img_size=(image_size[1], image_size[0]),
            patch_size=16,
            qkv_bias=True,
            final_norm=True,
            out_type='featmap',
            with_cls_token=False, # Shape Mismatch í•´ê²°
            patch_cfg=dict(padding=2),
            init_cfg=dict(type='Pretrained', checkpoint=str(ckpt_path)),
        ),
        head=dict(
            type='HeatmapHead',
            in_channels=1024,
            out_channels=133,
            # Weight Mismatch í•´ê²°
            deconv_out_channels=(768, 768),
            deconv_kernel_sizes=(4, 4),
            conv_out_channels=(768, 768),
            conv_kernel_sizes=(1, 1),
            loss=dict(type='KeypointMSELoss', use_target_weight=True),
            decoder=dict(
                type='UDPHeatmap',
                input_size=(image_size[0], image_size[1]),
                heatmap_size=(int(image_size[0]/4), int(image_size[1]/4)),
                sigma=6
            )
        ),
        test_cfg=dict(flip_test=True, flip_mode='heatmap', shift_heatmap=False)
    )
    
    dummy_dataloader = dict(
        dataset=dict(
            type='CocoWholeBodyDataset',
            pipeline=test_pipeline # ConfigDict Error í•´ê²°
        )
    )
    
    return Config(dict(
        model=model_cfg, 
        test_dataloader=dummy_dataloader,
        default_scope='mmpose'
    ))

# --- 6. Main: Keypoints ì¶”ì¶œ ---
def extract_keypoints(frame_dir, sam_dir, output_dir, pose_ckpt, device='cuda:0'):
    output_dir = Path(output_dir)
    if output_dir.exists():
        shutil.rmtree(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1. ëª¨ë¸ ì´ˆê¸°í™”
    register_all_modules()
    print(f"ğŸš€ Sapiens ëª¨ë¸ ë¡œë“œ ì¤‘... ({device})")
    
    try:
        cfg = get_sapiens_config(pose_ckpt)
        pose_estimator = init_model(cfg, str(pose_ckpt), device=device)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return 0

    # 2. íŒŒì¼ ëª©ë¡ ì²˜ë¦¬
    sam_dir = Path(sam_dir)
    frame_dir = Path(frame_dir)
    sam_files = sorted(list(sam_dir.glob("*.json")))
    print(f"ğŸ“‚ ì´ {len(sam_files)}ê°œì˜ í”„ë ˆì„ ì²˜ë¦¬ ì˜ˆì •")

    saved_count = 0

    # 3. í”„ë ˆì„ë³„ ë°˜ë³µ
    for sam_file in tqdm(sam_files, desc="Processing"):
        try:
            # SAM ì •ë³´ íŒŒì‹±
            file_name, objects = extract_bbox_and_id(str(sam_file))
            
            img_path = frame_dir / file_name
            if not img_path.exists(): continue
            
            img = cv2.imread(str(img_path))
            if img is None: continue

            # í•´ë‹¹ í”„ë ˆì„ì˜ ëª¨ë“  ì‚¬ëŒ ê²°ê³¼(PoseDataSample)ë¥¼ ëª¨ì„ ë¦¬ìŠ¤íŠ¸
            frame_pose_results = []

            # 4. ê°ì²´ë³„ Loop (Detection ëŒ€ì‹  SAM BBox ì‚¬ìš©)
            for obj in objects:
                bbox = obj['bbox']
                obj_id = obj['id']
                if not bbox: continue

                # A. Padding & Crop
                crop_img, padded_bbox = get_padded_crop(img, bbox, padding_ratio=0.2)
                if crop_img is None: continue

                # B. Inference
                h_crop, w_crop = crop_img.shape[:2]
                input_bbox = np.array([0, 0, w_crop, h_crop])
                
                # Sapiens ì¶”ë¡  (ê²°ê³¼ëŠ” PoseDataSample ë¦¬ìŠ¤íŠ¸)
                pose_results = inference_topdown(pose_estimator, crop_img, bboxes=input_bbox[None])
                
                # C. ì¢Œí‘œ ì›ë³µ (PoseDataSample ë‚´ë¶€ ë°ì´í„°ë¥¼ ì§ì ‘ ìˆ˜ì •)
                for res in pose_results:
                    # Keypoints ì›ë³µ [K, 2]
                    res.pred_instances.keypoints[0] += [padded_bbox[0], padded_bbox[1]]
                    
                    # BBox ì›ë³µ (Crop ê¸°ì¤€ -> ì›ë³¸ ì´ë¯¸ì§€ ê¸°ì¤€)
                    # Sapiensê°€ ì˜ˆì¸¡í•œ BBoxë¥¼ ì›ë³¸ ì¢Œí‘œê³„ë¡œ ì´ë™
                    res.pred_instances.bboxes[0] += [padded_bbox[0], padded_bbox[1], padded_bbox[0], padded_bbox[1]]

                    # ID ì •ë³´ë¥¼ ë©”íƒ€ë°ì´í„°ë‚˜ ë³„ë„ í•„ë“œì— ì¶”ê°€í•˜ê³  ì‹¶ì§€ë§Œ, 
                    # split_instances êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ì—¬ê¸°ì„œëŠ” í‘œì¤€ í¬ë§·ë§Œ ì‚¬ìš©
                    # (í•„ìš”í•˜ë‹¤ë©´ ë‚˜ì¤‘ì— instance_info ë¦¬ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ê°€ëŠ¥)
                    
                    frame_pose_results.append(res)

            # 5. ê²°ê³¼ í†µí•© ë° ì €ì¥ (MMPose í‘œì¤€ í¬ë§· ì‚¬ìš©)
            if frame_pose_results:
                # ì—¬ëŸ¬ ì‚¬ëŒì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ DataSampleë¡œ ë³‘í•©
                data_sample = merge_data_samples(frame_pose_results)
                
                # ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ ì¶”ì¶œ
                inst = data_sample.get("pred_instances", None)
                if inst is not None:
                    # ìš”ì²­í•˜ì‹  split_instances ì‚¬ìš© -> dict ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    inst_list = split_instances(inst)
                    
                    # í”„ë ˆì„ ë²ˆí˜¸ ì¶”ì¶œ
                    frame_idx = int(Path(file_name).stem) if Path(file_name).stem.isdigit() else 0
                    
                    payload = dict(
                        frame_index=frame_idx,
                        meta_info=pose_estimator.dataset_meta, # Skeleton ì •ë³´
                        instance_info=inst_list                # í‘œì¤€ í¬ë§· ì¸ìŠ¤í„´ìŠ¤ ì •ë³´
                    )
                    
                    save_path = output_dir / f"{Path(file_name).stem}.json"
                    with open(save_path, "w", encoding="utf-8") as f:
                        json.dump(to_py(payload), f, ensure_ascii=False, indent=2)
                    
                    saved_count += 1

        except Exception as e:
            print(f"[Error] {sam_file.name}: {e}")
            import traceback
            traceback.print_exc()
            continue

    return saved_count

if __name__ == "__main__":
    count = extract_keypoints(
        frame_dir=frame_path,
        sam_dir=sam_path,
        output_dir=output_json_dir,
        pose_ckpt=checkpoint_path
    )
    print(f"\nâœ… ì™„ë£Œ! ì´ {count}ê°œì˜ JSON íŒŒì¼ ìƒì„±ë¨.")
    print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {output_json_dir}")