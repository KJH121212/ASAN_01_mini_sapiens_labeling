import pandas as pd
from pathlib import Path

import sys
sys.path.append(str(Path(__file__).resolve().parent.parent))
from functions.run_sapiens_lite_inference import run_sapiens_lite_inference
from functions.generate_skeleton_video import generate_skeleton_video

import time

DATA_DIR = Path("/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data")
df = pd.read_csv(DATA_DIR / "metadata.csv")

for target in range(705,710):

    COMMON_PATH = df['common_path'][target]

    FRAME_DIR = DATA_DIR / "1_FRAME" / COMMON_PATH
    SAM_DIR = DATA_DIR / "8_SAM" / COMMON_PATH

    # COCO 133ì  ê¸°ë°˜
    # SEG_OUTPUT_DIR = DATA_DIR / "9_KEYPOINTS_V2" / COMMON_PATH
    # VIDEO_OUTPUT_PATH = DATA_DIR / "10_VIDEO_V2" / f"{COMMON_PATH}.mp4"
    # CONFIG = "/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_sapiens_labeling/configs/sapiens/sapiens_0.3b-210e_coco_wholebody-1024x768.py"
    # CKPT = DATA_DIR / "checkpoints/sapiens/pose/sapiens_0.3b_coco_wholebody_best_coco_wholebody_AP_620.pth"

    # # COCO 17ì  ê¸°ë°˜
    # SEG_OUTPUT_DIR = DATA_DIR / "test" / COMMON_PATH / "sapiens_lite_output"
    # VIDEO_OUTPUT_PATH = DATA_DIR / "test" / COMMON_PATH / "sapiens_lite_skeleton_video.mp4"
    # CONFIG = "/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_sapiens_labeling/configs/sapiens/sapiens_0.3b-210e_coco-1024x768.py"
    # CKPT = DATA_DIR / "checkpoints/sapiens/pose/sapiens_0.3b_coco_best_coco_AP_796.pth"

    # total_start_time = time.time()

    # SAPIENS-Lite ì¶”ë¡ 
    # step1_start_time = time.time()
    # count = run_sapiens_lite_inference(
    #     FRAME_DIR, 
    #     SAM_DIR, 
    #     output_dir=SEG_OUTPUT_DIR, 
    #     config_path=CONFIG, 
    #     ckpt_path=CKPT, 
    #     batch_size=30
    # )
    
    # step1_end_time = time.time()
    # print(f"âœ… ì™„ë£Œ: {count}ê°œ JSON ìƒì„±")

    # ë¹„ë””ì˜¤ ìƒì„±
    # step2_start_time = time.time()
    SEG_OUTPUT_DIR = DATA_DIR / "2_KEYPOINTS" / COMMON_PATH
    # v5.0: Full Model + Batch + SAM BBox + Gray Padding
    OUTPUT_DIR = DATA_DIR / "test" / COMMON_PATH / "ORIGIN_17kpt.mp4"
    generate_skeleton_video(
        frame_dir=FRAME_DIR,
        kpt_dir=SEG_OUTPUT_DIR,
        output_path=OUTPUT_DIR,
        conf_threshold=0
    )
    # step2_end_time = time.time()

    # # ëª…ì‹œì  ë©”ëª¨ë¦¬ ì •ë¦¬
    # import torch
    # import gc
    # torch.cuda.empty_cache()
    # gc.collect()

# =========================================================
# ğŸ“Š ì‘ì—… ì •ë¦¬ ë³´ê³ ì„œ (ê°œì„ ëœ ê°€ë…ì„± ë²„ì „)
# =========================================================

# # ì†Œìš” ì‹œê°„ ê³„ì‚°
# step1_elapsed = step1_end_time - step1_start_time
# step2_elapsed = step2_end_time - step2_start_time
# total_elapsed = time.time() - total_start_time

# def format_time(seconds):
#     """ì´ˆ ë‹¨ìœ„ ì‹œê°„ì„ ë¶„/ì´ˆ í˜•íƒœë¡œ ë³€í™˜"""
#     return f"{int(seconds // 60)}m {seconds % 60:.2f}s"

# print("\n" + "="*100)
# print(f"ğŸ“Œ WORK SUMMARY REPORT | ëŒ€ìƒ: {COMMON_PATH}")
# print("="*100)

# # í—¤ë” ì¶œë ¥
# print(f"{'ì‘ì—… ë‹¨ê³„':<25} | {'ê²°ê³¼ë¬¼ ìˆ˜':<15} | {'ì†Œìš” ì‹œê°„':<15}")
# print("-" * 100)

# # Step 1 ì¶œë ¥
# print(f"{'1. Sapiens Lite ì¶”ë¡ ':<25} | {f'{count} JSONs':<15} | {format_time(step1_elapsed):<15}")
# print(f"   ğŸ“‚ ê²½ë¡œ: {SEG_OUTPUT_DIR}")
# print("-" * 100)

# # Step 2 ì¶œë ¥
# print(f"{'2. ìŠ¤ì¼ˆë ˆí†¤ ë¹„ë””ì˜¤ ìƒì„±':<25} | {'1 MP4':<15} | {format_time(step2_elapsed):<15}")
# print(f"   ğŸ“‚ ê²½ë¡œ: {VIDEO_OUTPUT_PATH}")
# print("-" * 100)

# # ì „ì²´ ì´ê³„ ì¶œë ¥
# print(f"{'â­ ì „ì²´ ì´ê³„':<25} | {'-':<15} | {format_time(total_elapsed):<15}")
# print("="*100)