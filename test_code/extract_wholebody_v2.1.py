import sys
import os
import json
import shutil
import cv2
import numpy as np
import torch
from pathlib import Path
from tqdm import tqdm

# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ í•˜ì§€ ì•Šê³  ìƒë‹¨ ë°°ì¹˜) ---
try:
    from mmpose.apis import init_model, inference_topdown
    from mmengine import Config
    from mmpose.utils import register_all_modules
    from mmpose.structures import merge_data_samples, split_instances
except ImportError:
    print("âŒ MMPose ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    sys.exit(1)

# ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ (BBox ì¶”ì¶œìš©) - ê²½ë¡œ ë¬¸ì œ ë°œìƒ ì‹œ try-except
try:
    from functions.extract_bbox_and_id import extract_bbox_and_id
except ImportError:
    # ëª¨ë“ˆ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ í˜„ì¬ íŒŒì¼ ìƒìœ„ ê²½ë¡œ ì¶”ê°€
    current_file_path = Path(__file__).resolve()
    project_root = current_file_path.parent.parent 
    if str(project_root) not in sys.path:
        sys.path.append(str(project_root))
    try:
        from functions.extract_bbox_and_id import extract_bbox_and_id
    except ImportError:
        print("âŒ 'functions' ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ============================================================
# 1ï¸âƒ£ Helper Functions
# ============================================================
def to_py(obj):
    """numpy ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python ê°ì²´ë¡œ ë³€í™˜"""
    import numpy as _np
    if isinstance(obj, _np.ndarray): return obj.tolist()
    if isinstance(obj, (_np.floating,)): return float(obj)
    if isinstance(obj, (_np.integer,)): return int(obj)
    if isinstance(obj, dict): return {k: to_py(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple)): return [to_py(v) for v in obj]
    return obj

def get_padded_crop(image, bbox, padding_ratio=0.2):
    """BBox ì£¼ë³€ì— íŒ¨ë”©ì„ ì¶”ê°€í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ í¬ë¡­"""
    x1, y1, x2, y2 = bbox
    h, w = image.shape[:2]
    
    box_w = x2 - x1
    box_h = y2 - y1
    cx = x1 + box_w / 2
    cy = y1 + box_h / 2
    
    new_w = box_w * (1 + padding_ratio)
    new_h = box_h * (1 + padding_ratio)
    
    new_x1 = int(cx - new_w / 2)
    new_y1 = int(cy - new_h / 2)
    new_x2 = int(cx + new_w / 2)
    new_y2 = int(cy + new_h / 2)
    
    new_x1 = max(0, new_x1)
    new_y1 = max(0, new_y1)
    new_x2 = min(w, new_x2)
    new_y2 = min(h, new_y2)
    
    if new_x2 <= new_x1 or new_y2 <= new_y1:
        return None, None

    crop_img = image[new_y1:new_y2, new_x1:new_x2]
    return crop_img, [new_x1, new_y1, new_x2, new_y2]

def get_sapiens_config(ckpt_path):
    """Sapiens Config ìƒì„± (í•˜ë“œì½”ë”©)"""
    image_size = [768, 1024]
    
    test_pipeline = [
        dict(type='LoadImage'),
        dict(type='GetBBoxCenterScale'),
        dict(type='TopdownAffine', input_size=image_size, use_udp=True),
        dict(type='PackPoseInputs')
    ]

    model_cfg = dict(
        type='TopdownPoseEstimator',
        data_preprocessor=dict(type='PoseDataPreprocessor', mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], bgr_to_rgb=True),
        backbone=dict(
            type='mmpretrain.VisionTransformer',
            arch=dict(embed_dims=1024, num_layers=24, num_heads=16, feedforward_channels=4096),
            img_size=(image_size[1], image_size[0]), patch_size=16, qkv_bias=True, final_norm=True, out_type='featmap',
            with_cls_token=False, patch_cfg=dict(padding=2), init_cfg=dict(type='Pretrained', checkpoint=str(ckpt_path)),
        ),
        head=dict(
            type='HeatmapHead', in_channels=1024, out_channels=133,
            deconv_out_channels=(768, 768), deconv_kernel_sizes=(4, 4),
            conv_out_channels=(768, 768), conv_kernel_sizes=(1, 1),
            loss=dict(type='KeypointMSELoss', use_target_weight=True),
            decoder=dict(type='UDPHeatmap', input_size=(image_size[0], image_size[1]), heatmap_size=(int(image_size[0]/4), int(image_size[1]/4)), sigma=6)
        ),
        test_cfg=dict(flip_test=True, flip_mode='heatmap', shift_heatmap=False)
    )
    
    dummy_dataloader = dict(dataset=dict(type='CocoWholeBodyDataset', pipeline=test_pipeline))
    return Config(dict(model=model_cfg, test_dataloader=dummy_dataloader, default_scope='mmpose'))

# ============================================================
# 2ï¸âƒ£ Main Function: Keypoints ì¶”ì¶œ
# ============================================================
def extract_keypoints(frame_dir: str, sam_dir: str, output_dir: str, 
                      pose_ckpt: str, device: str = 'cuda:0') -> int:
    """
    Sapiens ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ Keypointsë¥¼ ì¶”ì¶œí•˜ê³  JSONìœ¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜.
    
    Args:
        frame_dir (str): ì›ë³¸ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
        sam_dir (str): SAM ê²°ê³¼(BBox í¬í•¨) JSON íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œ
        output_dir (str): ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œ
        pose_ckpt (str): Sapiens ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸(.pth) íŒŒì¼ ê²½ë¡œ
        device (str): ì‹¤í–‰ ì¥ì¹˜ (ê¸°ë³¸: 'cuda:0')
        
    Returns:
        int: ìƒì„±ëœ JSON íŒŒì¼ ê°œìˆ˜
    """
    
    # ê²½ë¡œ ê°ì²´ ë³€í™˜
    frame_dir = Path(frame_dir)
    sam_dir = Path(sam_dir)
    output_dir = Path(output_dir)
    
    # ì¶œë ¥ í´ë” ì´ˆê¸°í™”
    if output_dir.exists():
        shutil.rmtree(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1. ëª¨ë¸ ì´ˆê¸°í™”
    register_all_modules()
    print(f"ğŸš€ Sapiens ëª¨ë¸ ë¡œë“œ ì¤‘... ({device})")
    
    try:
        cfg = get_sapiens_config(pose_ckpt)
        pose_estimator = init_model(cfg, str(pose_ckpt), device=device)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return 0

    # 2. íŒŒì¼ ëª©ë¡ ì¤€ë¹„
    sam_files = sorted(list(sam_dir.glob("*.json")))
    print(f"ğŸ“‚ ì´ {len(sam_files)}ê°œì˜ í”„ë ˆì„ ì²˜ë¦¬ ì˜ˆì •")

    saved_count = 0

    # 3. í”„ë ˆì„ë³„ ë°˜ë³µ ì²˜ë¦¬
    for sam_file in tqdm(sam_files, desc="Processing"):
        try:
            # SAM JSON íŒŒì‹± (íŒŒì¼ëª… ë° BBox ì¶”ì¶œ)
            file_name, objects = extract_bbox_and_id(str(sam_file))
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            img_path = frame_dir / file_name
            if not img_path.exists(): continue
            
            img = cv2.imread(str(img_path))
            if img is None: continue

            frame_pose_results = []

            # 4. ê°ì²´ë³„ Loop
            for obj in objects:
                bbox = obj['bbox']
                if not bbox: continue

                # [Step A] Padding & Crop
                crop_img, padded_bbox = get_padded_crop(img, bbox, padding_ratio=0.2)
                if crop_img is None: continue

                # [Step B] Inference
                h_crop, w_crop = crop_img.shape[:2]
                input_bbox = np.array([0, 0, w_crop, h_crop])
                
                # Sapiens ì¶”ë¡ 
                pose_results = inference_topdown(pose_estimator, crop_img, bboxes=input_bbox[None])
                
                # [Step C] ì¢Œí‘œ ì›ë³µ (Remap)
                for res in pose_results:
                    res.pred_instances.keypoints[0] += [padded_bbox[0], padded_bbox[1]]
                    res.pred_instances.bboxes[0] += [padded_bbox[0], padded_bbox[1], padded_bbox[0], padded_bbox[1]]
                    frame_pose_results.append(res)

            # 5. ê²°ê³¼ ì €ì¥
            if frame_pose_results:
                data_sample = merge_data_samples(frame_pose_results)
                inst = data_sample.get("pred_instances", None)
                if inst is not None:
                    inst_list = split_instances(inst)
                    
                    # SAM ID ë§¤í•‘
                    for i, item in enumerate(inst_list):
                        if i < len(objects):
                            item['instance_id'] = objects[i]['id']
                    
                    frame_idx = int(Path(file_name).stem) if Path(file_name).stem.isdigit() else 0
                    
                    payload = dict(
                        frame_index=frame_idx,
                        file_name=file_name,
                        meta_info=pose_estimator.dataset_meta,
                        instance_info=inst_list
                    )
                    
                    save_path = output_dir / f"{Path(file_name).stem}.json"
                    with open(save_path, "w", encoding="utf-8") as f:
                        json.dump(to_py(payload), f, ensure_ascii=False, indent=2)
                    
                    saved_count += 1

        except Exception as e:
            print(f"[Error] {sam_file.name}: {e}")
            continue

    return saved_count

# ============================================================
# ì‹¤í–‰ ì˜ˆì‹œ (ì§ì ‘ ì‹¤í–‰ ì‹œ)
# ============================================================
if __name__ == "__main__":

    DATA_DIR = Path("/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data")
    FRAME_DIR = DATA_DIR / "walking_data/FRAME/frontal__walking__1"
    SAM_DIR = DATA_DIR / "walking_data/sam/frontal__walking__1"
    OUTPUT_DIR = DATA_DIR / "walking_data/sapiens/frontal__walking__1"
    CKPT_PATH = DATA_DIR / "checkpoints/sapiens/pose/sapiens_0.3b_coco_wholebody_best_coco_wholebody_AP_620.pth"

    count = extract_keypoints(FRAME_DIR, SAM_DIR, OUTPUT_DIR, CKPT_PATH)
    print(f"âœ… ì™„ë£Œ: {count}ê°œ íŒŒì¼ ìƒì„±")

    FRAME_DIR = DATA_DIR / "walking_data/FRAME/lateral__walking__1"
    SAM_DIR = DATA_DIR / "walking_data/sam/lateral__walking__1"
    OUTPUT_DIR = DATA_DIR / "walking_data/sapiens/lateral__walking__1"
    CKPT_PATH = DATA_DIR / "checkpoints/sapiens/pose/sapiens_0.3b_coco_wholebody_best_coco_wholebody_AP_620.pth"

    count = extract_keypoints(FRAME_DIR, SAM_DIR, OUTPUT_DIR, CKPT_PATH)
    print(f"âœ… ì™„ë£Œ: {count}ê°œ íŒŒì¼ ìƒì„±")