import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm

def analyze_score_auto_scale(input_dir, kpt_idx, output_dir):
    input_path = Path(input_dir)
    save_path = Path(output_dir)
    save_path.mkdir(parents=True, exist_ok=True)

    # 1. JSON ë¡œë”©
    json_files = sorted(list(input_path.glob("*.json")), key=lambda x: int(x.stem) if x.stem.isdigit() else x.stem)
    if not json_files: return

    frames = []
    scores = []

    print(f"ğŸ“‚ [{kpt_idx}ë²ˆ Keypoint] ë°ì´í„° ë¡œë”© ì¤‘... ({len(json_files)} frames)")

    for f_path in tqdm(json_files):
        with open(f_path, 'r') as f:
            data = json.load(f)
        if not data.get('instance_info'): continue
        kpts = data['instance_info'][0]['keypoints']
        
        if kpt_idx < len(kpts):
            s = kpts[kpt_idx][2]
            frames.append(int(f_path.stem) if f_path.stem.isdigit() else len(frames))
            scores.append(s)

    scores = np.array(scores)
    frames = np.array(frames)

    # 2. í†µê³„ ë° ë²”ìœ„ ê³„ì‚° (Auto Scaling)
    if len(scores) == 0: return

    mean_score = np.mean(scores)
    max_score = np.max(scores)
    min_score = np.min(scores)
    
    # ê·¸ë˜í”„ ë²”ìœ„ë¥¼ ë°ì´í„°ì˜ min/maxì— ì•½ê°„ì˜ ì—¬ìœ ë¥¼ ë‘¬ì„œ ì„¤ì •
    y_min = max(0, min_score - (max_score - min_score) * 0.1)
    y_max = max_score + (max_score - min_score) * 0.1
    
    # ë§Œì•½ ëª¨ë“  ê°’ì´ 0ì´ë©´ ê°•ì œë¡œ 0~0.01 ì„¤ì •
    if y_max == 0: y_max = 0.01

    print(f"ğŸ“Š Auto-Scaling ì ìš©: {min_score:.6f} ~ {max_score:.6f}")

    # 3. ì‹œê°í™”
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, axes = plt.subplots(1, 2, figsize=(18, 6))
    fig.suptitle(f"Confidence Score Analysis (Auto-Scaled): ID {kpt_idx}", fontsize=16, fontweight='bold')

    # [ì¢Œì¸¡] Histogram (ë°ì´í„° ë²”ìœ„ì— ë§ì¶¤)
    # binsë¥¼ 0~1 ê³ ì •ì´ ì•„ë‹ˆë¼, ì‹¤ì œ ë°ì´í„° ë²”ìœ„(min~max)ë¡œ ì„¤ì •
    axes[0].hist(scores, bins=50, color='royalblue', edgecolor='black', alpha=0.7)
    axes[0].set_title(f"Score Distribution ({min_score:.4f}~{max_score:.4f})", fontsize=14)
    axes[0].set_xlabel("Confidence Score")
    axes[0].set_ylabel("Count")
    axes[0].axvline(mean_score, color='red', linestyle='--', label=f'Mean: {mean_score:.4f}')
    axes[0].legend()

    # [ìš°ì¸¡] Timeline (Yì¶• ìë™ í™•ëŒ€)
    axes[1].plot(frames, scores, color='darkviolet', linewidth=1, alpha=0.8)
    axes[1].set_title(f"Score Trend (Zoomed In)", fontsize=14)
    axes[1].set_xlabel("Frame Index")
    axes[1].set_ylabel("Score")
    
    # ğŸ”´ ì—¬ê¸°ê°€ í•µì‹¬: Yì¶• ë²”ìœ„ë¥¼ ë°ì´í„°ì— ë§ì¶¤
    axes[1].set_ylim(y_min, y_max)
    
    # í‰ê· ì„  í‘œì‹œ
    axes[1].axhline(mean_score, color='red', linestyle='--', alpha=0.5, label='Mean')
    axes[1].legend()

    plt.tight_layout()

    # ì €ì¥
    file_name = f"eda_score_auto_kpt{kpt_idx:03d}.png"
    out_file = save_path / file_name
    plt.savefig(out_file, dpi=150)
    plt.close()
    
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {out_file}")

# ============================================================
if __name__ == "__main__":
    DATA_DIR = Path("/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data")
    df = pd.read_csv(DATA_DIR / "metadata.csv")
    
    target = 4
    COMMON_PATH = df['common_path'][target]
    INPUT_DIR = DATA_DIR / "9_KEYPOINTS_V2" / COMMON_PATH
    OUTPUT_DIR = "/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_sapiens_labeling/eda_results"
    
    TARGET_KEYPOINT = 6
    analyze_score_auto_scale(INPUT_DIR, TARGET_KEYPOINT, OUTPUT_DIR)