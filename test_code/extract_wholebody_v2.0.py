import sys
import os
import json
import shutil
import cv2
import numpy as np
import pandas as pd
import torch
from pathlib import Path
from tqdm import tqdm

# --- 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ---
# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì • (ëª¨ë“ˆ import ë¬¸ì œ í•´ê²°)
current_file_path = Path(__file__).resolve()
project_root = current_file_path.parent.parent 
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

# ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ (BBox ì¶”ì¶œìš©)
try:
    from functions.extract_bbox_and_id import extract_bbox_and_id
except ImportError:
    print("âŒ 'functions' ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# MMPose ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ
try:
    from mmpose.apis import init_model, inference_topdown
    from mmengine import Config
    from mmpose.utils import register_all_modules
    # ìµœì¢… ê²°ê³¼ í¬ë§·ì„ ë§ì¶”ê¸° ìœ„í•œ í•¨ìˆ˜ë“¤
    from mmpose.structures import merge_data_samples, split_instances
except ImportError:
    print("âŒ MMPose ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# --- 2. ê²½ë¡œ ì„¤ì • ---
data_path = Path("/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data")
base_path = project_root 

# ë©”íƒ€ë°ì´í„° ë¡œë“œ
df_path = data_path / "metadata.csv"
if not df_path.exists():
    print(f"âŒ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì—†ìŒ: {df_path}")
    sys.exit(1)
    
df = pd.read_csv(df_path)
common_path = df['common_path'][1] # ì‚¬ìš©ìê°€ ì§€ì •í•œ ì¸ë±ìŠ¤ [1] ì‚¬ìš©

checkpoint_path = data_path / "checkpoints/sapiens/pose/sapiens_0.3b_coco_wholebody_best_coco_wholebody_AP_620.pth"
frame_path = data_path / "1_FRAME" / common_path
sam_path = data_path / "8_SAM" / common_path
output_json_dir = base_path / "test" / "keypoints_result_v2.0" # ê²°ê³¼ ì €ì¥ ê²½ë¡œ

# --- 3. Helper: Numpy -> JSON ë³€í™˜ ---
def to_py(obj):
    """numpy ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python ê°ì²´ë¡œ ë³€í™˜"""
    import numpy as _np
    if isinstance(obj, _np.ndarray): 
        return obj.tolist()
    if isinstance(obj, (_np.floating,)): 
        return float(obj)
    if isinstance(obj, (_np.integer,)):  
        return int(obj)
    if isinstance(obj, dict):  
        return {k: to_py(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple)): 
        return [to_py(v) for v in obj]
    return obj

# --- 4. Helper: Padding & Crop í•¨ìˆ˜ (í•µì‹¬) ---
def get_padded_crop(image, bbox, padding_ratio=0.2):
    """
    BBox ì£¼ë³€ì— íŒ¨ë”©ì„ ì¶”ê°€í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ í¬ë¡­í•©ë‹ˆë‹¤.
    Args:
        image: ì›ë³¸ ì´ë¯¸ì§€ (H, W, C)
        bbox: [x1, y1, x2, y2]
        padding_ratio: íŒ¨ë”© ë¹„ìœ¨ (ê¸°ë³¸ 0.2 = 20%)
    Returns:
        crop_img: ì˜ë¼ë‚¸ ì´ë¯¸ì§€
        padded_bbox: [new_x1, new_y1, new_x2, new_y2] (ì¢Œí‘œ ì›ë³µìš© ì˜¤í”„ì…‹)
    """
    x1, y1, x2, y2 = bbox
    h, w = image.shape[:2]
    
    # BBox ë„ˆë¹„/ë†’ì´ ê³„ì‚°
    box_w = x2 - x1
    box_h = y2 - y1
    
    # ì¤‘ì‹¬ì  ê³„ì‚°
    cx = x1 + box_w / 2
    cy = y1 + box_h / 2
    
    # íŒ¨ë”© ì ìš©ëœ ìƒˆ ë„ˆë¹„/ë†’ì´ (20% í™•ì¥)
    new_w = box_w * (1 + padding_ratio)
    new_h = box_h * (1 + padding_ratio)
    
    # ìƒˆ ì¢Œí‘œ ê³„ì‚° (ì •ìˆ˜í˜• ë³€í™˜)
    new_x1 = int(cx - new_w / 2)
    new_y1 = int(cy - new_h / 2)
    new_x2 = int(cx + new_w / 2)
    new_y2 = int(cy + new_h / 2)
    
    # ì´ë¯¸ì§€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ Clip ì²˜ë¦¬ (ë§¤ìš° ì¤‘ìš”)
    new_x1 = max(0, new_x1)
    new_y1 = max(0, new_y1)
    new_x2 = min(w, new_x2)
    new_y2 = min(h, new_y2)
    
    # ìœ íš¨ì„± ê²€ì‚¬: í¬ë¡­ ì˜ì—­ì´ ì—†ìœ¼ë©´ None ë°˜í™˜
    if new_x2 <= new_x1 or new_y2 <= new_y1:
        return None, None

    # ì´ë¯¸ì§€ í¬ë¡­ (NumPy ìŠ¬ë¼ì´ì‹±)
    crop_img = image[new_y1:new_y2, new_x1:new_x2]
    
    # ì˜ë¦° ì˜ì—­ì˜ ì¢Œí‘œ ë°˜í™˜ (ë‚˜ì¤‘ì— ì›ë³µí•  ë•Œ í•„ìš”)
    return crop_img, [new_x1, new_y1, new_x2, new_y2]

# --- 5. Helper: Sapiens Config ìƒì„± (í•˜ë“œì½”ë”© ë°©ì‹) ---
def get_sapiens_config(ckpt_path):
    """
    Config íŒŒì¼ì„ ì½ì§€ ì•Šê³  Python ì½”ë“œë¡œ ì§ì ‘ ì„¤ì •ì„ ìƒì„±í•©ë‹ˆë‹¤.
    (ê²½ë¡œ ì—ëŸ¬ ë° ì•„í‚¤í…ì²˜ ë¯¸ë“±ë¡ ì—ëŸ¬ë¥¼ ì›ì²œ ì°¨ë‹¨)
    """
    image_size = [768, 1024] # Width, Height
    
    # Pipeline ì •ì˜ (inference_topdown í•¨ìˆ˜ê°€ í•„ìš”ë¡œ í•¨)
    test_pipeline = [
        dict(type='LoadImage'),
        dict(type='GetBBoxCenterScale'),
        dict(type='TopdownAffine', input_size=image_size, use_udp=True),
        dict(type='PackPoseInputs')
    ]

    model_cfg = dict(
        type='TopdownPoseEstimator',
        data_preprocessor=dict(
            type='PoseDataPreprocessor',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            bgr_to_rgb=True
        ),
        backbone=dict(
            type='mmpretrain.VisionTransformer',
            # Sapiens 0.3b (ViT-Large) ì•„í‚¤í…ì²˜ ì‚¬ì–‘ ì§ì ‘ ì£¼ì…
            arch=dict(
                embed_dims=1024, num_layers=24, num_heads=16, feedforward_channels=4096
            ),
            img_size=(image_size[1], image_size[0]),
            patch_size=16,
            qkv_bias=True,
            final_norm=True,
            out_type='featmap',
            with_cls_token=False, # Shape Mismatch í•´ê²°ì„ ìœ„í•´ False ì„¤ì •
            patch_cfg=dict(padding=2),
            init_cfg=dict(type='Pretrained', checkpoint=str(ckpt_path)),
        ),
        head=dict(
            type='HeatmapHead',
            in_channels=1024,
            out_channels=133,
            # Weight Mismatch í•´ê²°ì„ ìœ„í•´ ì±„ë„ ìˆ˜ ëª…ì‹œ (768)
            deconv_out_channels=(768, 768),
            deconv_kernel_sizes=(4, 4),
            conv_out_channels=(768, 768),
            conv_kernel_sizes=(1, 1),
            loss=dict(type='KeypointMSELoss', use_target_weight=True),
            decoder=dict(
                type='UDPHeatmap',
                input_size=(image_size[0], image_size[1]),
                heatmap_size=(int(image_size[0]/4), int(image_size[1]/4)),
                sigma=6
            )
        ),
        test_cfg=dict(flip_test=True, flip_mode='heatmap', shift_heatmap=False)
    )
    
    # Dataloaderì— Pipeline ì£¼ì… (ConfigDict Error í•´ê²°)
    dummy_dataloader = dict(
        dataset=dict(
            type='CocoWholeBodyDataset',
            pipeline=test_pipeline 
        )
    )
    gv
    return Config(dict(
        model=model_cfg, 
        test_dataloader=dummy_dataloader,
        default_scope='mmpose'
    ))

# --- 6. Main: Keypoints ì¶”ì¶œ í•¨ìˆ˜ ---
def extract_keypoints(frame_dir, sam_dir, output_dir, pose_ckpt, device='cuda:0'):
    # ì¶œë ¥ í´ë” ì´ˆê¸°í™” (ê¸°ì¡´ í´ë” ì‚­ì œ í›„ ì¬ìƒì„±)
    output_dir = Path(output_dir)
    if output_dir.exists():
        shutil.rmtree(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1. ëª¨ë¸ ì´ˆê¸°í™”
    register_all_modules()
    print(f"ğŸš€ Sapiens ëª¨ë¸ ë¡œë“œ ì¤‘... ({device})")
    
    try:
        cfg = get_sapiens_config(pose_ckpt)
        pose_estimator = init_model(cfg, str(pose_ckpt), device=device)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return 0

    # 2. íŒŒì¼ ëª©ë¡ ì¤€ë¹„ (SAM JSON íŒŒì¼ ê¸°ì¤€)
    sam_dir = Path(sam_dir)
    frame_dir = Path(frame_dir)
    sam_files = sorted(list(sam_dir.glob("*.json")))
    print(f"ğŸ“‚ ì´ {len(sam_files)}ê°œì˜ í”„ë ˆì„ ì²˜ë¦¬ ì˜ˆì •")

    saved_count = 0

    # 3. í”„ë ˆì„ë³„ ë°˜ë³µ ì²˜ë¦¬
    for sam_file in tqdm(sam_files, desc="Processing"):
        try:
            # SAM JSONì—ì„œ íŒŒì¼ëª…ê³¼ ê°ì²´ ì •ë³´ ì¶”ì¶œ
            file_name, objects = extract_bbox_and_id(str(sam_file))
            
            # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸ ë° ë¡œë“œ
            img_path = frame_dir / file_name
            if not img_path.exists(): continue
            
            img = cv2.imread(str(img_path))
            if img is None: continue

            # í•´ë‹¹ í”„ë ˆì„ì˜ ëª¨ë“  ì‚¬ëŒ ê²°ê³¼(PoseDataSample)ë¥¼ ëª¨ì„ ë¦¬ìŠ¤íŠ¸
            frame_pose_results = []

            # 4. ê°ì²´ë³„ Loop (Detection ìƒëµ, SAM BBox ì‚¬ìš©)
            for obj in objects:
                bbox = obj['bbox'] # [x1, y1, x2, y2]
                obj_id = obj['id']
                if not bbox: continue

                # [Step A] Padding & Crop
                # ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ BBox ì˜ì—­ì„ ì˜ë¼ëƒ…ë‹ˆë‹¤.
                crop_img, padded_bbox = get_padded_crop(img, bbox, padding_ratio=0.2)
                if crop_img is None: continue

                # [Step B] Inference
                # ì˜ë¦° ì´ë¯¸ì§€(crop_img)ë¥¼ ëª¨ë¸ì— ë„£ìŠµë‹ˆë‹¤.
                # ì´ë•Œ BBoxëŠ” ì´ë¯¸ì§€ ì „ì²´ í¬ê¸°([0, 0, w, h])ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
                h_crop, w_crop = crop_img.shape[:2]
                input_bbox = np.array([0, 0, w_crop, h_crop])
                
                # Sapiens ì¶”ë¡  ì‹¤í–‰
                pose_results = inference_topdown(pose_estimator, crop_img, bboxes=input_bbox[None])
                
                # [Step C] ì¢Œí‘œ ì›ë³µ (Remap)
                # ì¶”ë¡  ê²°ê³¼ëŠ” ì˜ë¦° ì´ë¯¸ì§€ ê¸°ì¤€ ì¢Œí‘œì´ë¯€ë¡œ, 
                # ì˜ë¼ë‚¸ ì‹œì‘ì (px1, py1)ì„ ë”í•´ì„œ ì›ë³¸ ì¢Œí‘œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
                for res in pose_results:
                    # Keypoints ì›ë³µ: [x, y] += [padding_x1, padding_y1]
                    res.pred_instances.keypoints[0] += [padded_bbox[0], padded_bbox[1]]
                    
                    # BBox ì›ë³µ: Sapiensê°€ ì˜ˆì¸¡í•œ BBoxë„ ì›ë³¸ ì¢Œí‘œê³„ë¡œ ì´ë™
                    res.pred_instances.bboxes[0] += [padded_bbox[0], padded_bbox[1], padded_bbox[0], padded_bbox[1]]

                    # ID ì •ë³´ë¥¼ ì—¬ê¸°ì— ì§ì ‘ ë„£ì„ ìˆ˜ëŠ” ì—†ì§€ë§Œ(MMPose êµ¬ì¡°ìƒ),
                    # ì•„ë˜ì—ì„œ split_instances í›„ instance_infoë¥¼ ë§Œë“¤ ë•Œ SAM IDë¥¼ ë§¤í•‘í•´ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    
                    frame_pose_results.append(res)

            # 5. ê²°ê³¼ í†µí•© ë° ì €ì¥ (MMPose í‘œì¤€ í¬ë§· ì¤€ìˆ˜)
            if frame_pose_results:
                # ì—¬ëŸ¬ ì‚¬ëŒì˜ ê²°ê³¼(DataSamples)ë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©
                data_sample = merge_data_samples(frame_pose_results)
                
                # ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ ì¶”ì¶œ
                inst = data_sample.get("pred_instances", None)
                if inst is not None:
                    # split_instancesë¥¼ ì‚¬ìš©í•´ í‘œì¤€ dict ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    inst_list = split_instances(inst)
                    
                    # [ì¤‘ìš”] SAM ê°ì²´ ìˆœì„œì™€ inst_list ìˆœì„œê°€ ë™ì¼í•˜ë‹¤ê³  ê°€ì •í•˜ê³  ID ë§¤í•‘
                    # (ì‹¤ì œë¡œëŠ” ìœ„ loop ìˆœì„œëŒ€ë¡œ append í–ˆìœ¼ë¯€ë¡œ ìˆœì„œê°€ ìœ ì§€ë©ë‹ˆë‹¤)
                    for i, item in enumerate(inst_list):
                        if i < len(objects):
                            item['instance_id'] = objects[i]['id'] # SAM ID ì¶”ê°€
                    
                    # í”„ë ˆì„ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: 000123.jpg -> 123)
                    frame_idx = int(Path(file_name).stem) if Path(file_name).stem.isdigit() else 0
                    
                    # ìµœì¢… ì €ì¥ ë°ì´í„° êµ¬ì„±
                    payload = dict(
                        frame_index=frame_idx,
                        file_name=file_name, # ì›ë³¸ íŒŒì¼ëª…ë„ ì €ì¥í•˜ë©´ ì¢‹ìŒ
                        meta_info=pose_estimator.dataset_meta, # Skeleton ë©”íƒ€ ì •ë³´
                        instance_info=inst_list                # Keypoints ì •ë³´
                    )
                    
                    # JSON íŒŒì¼ ì €ì¥
                    save_path = output_dir / f"{Path(file_name).stem}.json"
                    with open(save_path, "w", encoding="utf-8") as f:
                        json.dump(to_py(payload), f, ensure_ascii=False, indent=2)
                    
                    saved_count += 1

        except Exception as e:
            print(f"[Error] {sam_file.name}: {e}")
            import traceback
            traceback.print_exc()
            continue

    return saved_count

if __name__ == "__main__":
    count = extract_keypoints(
        frame_dir=frame_path,
        sam_dir=sam_path,
        output_dir=output_json_dir,
        pose_ckpt=checkpoint_path
    )
    print(f"\nâœ… ì™„ë£Œ! ì´ {count}ê°œì˜ JSON íŒŒì¼ ìƒì„±ë¨.")
    print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {output_json_dir}")