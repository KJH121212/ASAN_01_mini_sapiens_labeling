import sys
import os
import json
import shutil
import cv2
import numpy as np
import pandas as pd
import torch
from pathlib import Path
from tqdm import tqdm

# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
try:
    from mmpose.apis import init_model, inference_topdown
    from mmengine import Config
    from mmpose.utils import register_all_modules
    from mmpose.structures import merge_data_samples, split_instances
except ImportError:
    print("âŒ MMPose ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    sys.exit(1)

# ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ (BBox ì¶”ì¶œìš©)
try:
    from functions.extract_bbox_and_id import extract_bbox_and_id
except ImportError:
    # ê²½ë¡œ ë¬¸ì œ ëŒ€ë¹„
    current_file_path = Path(__file__).resolve()
    project_root = current_file_path.parent.parent 
    if str(project_root) not in sys.path:
        sys.path.append(str(project_root))
    try:
        from functions.extract_bbox_and_id import extract_bbox_and_id
    except ImportError:
        print("âŒ 'functions' ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ============================================================
# 1ï¸âƒ£ Helper Functions
# ============================================================
def to_py(obj):
    """numpy ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python ê°ì²´ë¡œ ë³€í™˜"""
    import numpy as _np
    if isinstance(obj, _np.ndarray): return obj.tolist()
    if isinstance(obj, (_np.floating,)): return float(obj)
    if isinstance(obj, (_np.integer,)): return int(obj)
    if isinstance(obj, dict): return {k: to_py(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple)): return [to_py(v) for v in obj]
    return obj

def get_padded_crop(image, bbox, padding_ratio=0.2):
    """BBox ì£¼ë³€ì— íŒ¨ë”©ì„ ì¶”ê°€í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ í¬ë¡­"""
    x1, y1, x2, y2 = bbox
    h, w = image.shape[:2]
    
    box_w = x2 - x1
    box_h = y2 - y1
    cx = x1 + box_w / 2
    cy = y1 + box_h / 2
    
    new_w = box_w * (1 + padding_ratio)
    new_h = box_h * (1 + padding_ratio)
    
    new_x1 = int(cx - new_w / 2)
    new_y1 = int(cy - new_h / 2)
    new_x2 = int(cx + new_w / 2)
    new_y2 = int(cy + new_h / 2)
    
    new_x1 = max(0, new_x1)
    new_y1 = max(0, new_y1)
    new_x2 = min(w, new_x2)
    new_y2 = min(h, new_y2)
    
    if new_x2 <= new_x1 or new_y2 <= new_y1:
        return None, None

    crop_img = image[new_y1:new_y2, new_x1:new_x2]
    return crop_img, [new_x1, new_y1, new_x2, new_y2]

# ============================================================
# 2ï¸âƒ£ Main Function: Keypoints ì¶”ì¶œ
# ============================================================
def extract_keypoints(frame_dir: str, sam_dir: str, output_dir: str, 
                      pose_config: str, pose_ckpt: str, device: str = 'cuda:0') -> int:
    """
    Sapiens ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ Keypointsë¥¼ ì¶”ì¶œí•˜ê³  JSONìœ¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜.
    
    Args:
        frame_dir (str): ì›ë³¸ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
        sam_dir (str): SAM ê²°ê³¼(BBox í¬í•¨) JSON íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œ
        output_dir (str): ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œ
        pose_config (str): Sapiens ëª¨ë¸ Config íŒŒì¼(.py) ê²½ë¡œ
        pose_ckpt (str): Sapiens ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸(.pth) íŒŒì¼ ê²½ë¡œ
        device (str): ì‹¤í–‰ ì¥ì¹˜ (ê¸°ë³¸: 'cuda:0')
        
    Returns:
        int: ìƒì„±ëœ JSON íŒŒì¼ ê°œìˆ˜
    """
    
    # ê²½ë¡œ ê°ì²´ ë³€í™˜
    frame_dir = Path(frame_dir)
    sam_dir = Path(sam_dir)
    output_dir = Path(output_dir)
    
    # ì¶œë ¥ í´ë” ì´ˆê¸°í™”
    if output_dir.exists():
        shutil.rmtree(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1. ëª¨ë¸ ì´ˆê¸°í™”
    register_all_modules()
    print(f"ğŸš€ Sapiens ëª¨ë¸ ë¡œë“œ ì¤‘... ({device})")
    print(f"   Config: {Path(pose_config).name}")
    
    try:
        # Config íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì´ˆê¸°í™”
        pose_estimator = init_model(pose_config, pose_ckpt, device=device)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return 0

    # 2. íŒŒì¼ ëª©ë¡ ì¤€ë¹„
    sam_files = sorted(list(sam_dir.glob("*.json")))
    print(f"ğŸ“‚ ì´ {len(sam_files)}ê°œì˜ í”„ë ˆì„ ì²˜ë¦¬ ì˜ˆì •")

    saved_count = 0

    # 3. í”„ë ˆì„ë³„ ë°˜ë³µ ì²˜ë¦¬
    for sam_file in tqdm(sam_files, desc="Processing"):
        try:
            # SAM JSON íŒŒì‹± (íŒŒì¼ëª… ë° BBox ì¶”ì¶œ)
            file_name, objects = extract_bbox_and_id(str(sam_file))
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            img_path = frame_dir / file_name
            if not img_path.exists(): continue
            
            img = cv2.imread(str(img_path))
            if img is None: continue

            frame_pose_results = []

            # 4. ê°ì²´ë³„ Loop
            for obj in objects:
                bbox = obj['bbox']
                if not bbox: continue

                # [Step A] Padding & Crop
                crop_img, padded_bbox = get_padded_crop(img, bbox, padding_ratio=0.2)
                if crop_img is None: continue

                # [Step B] Inference
                h_crop, w_crop = crop_img.shape[:2]
                input_bbox = np.array([0, 0, w_crop, h_crop])
                
                # Sapiens ì¶”ë¡ 
                pose_results = inference_topdown(pose_estimator, crop_img, bboxes=input_bbox[None])
                
                # [Step C] ì¢Œí‘œ ì›ë³µ (Remap)
                for res in pose_results:
                    res.pred_instances.keypoints[0] += [padded_bbox[0], padded_bbox[1]]
                    res.pred_instances.bboxes[0] += [padded_bbox[0], padded_bbox[1], padded_bbox[0], padded_bbox[1]]
                    frame_pose_results.append(res)

            # 5. ê²°ê³¼ ì €ì¥
            if frame_pose_results:
                data_sample = merge_data_samples(frame_pose_results)
                inst = data_sample.get("pred_instances", None)
                if inst is not None:
                    inst_list = split_instances(inst)
                    
                    # SAM ID ë§¤í•‘
                    for i, item in enumerate(inst_list):
                        if i < len(objects):
                            item['instance_id'] = objects[i]['id']
                    
                    frame_idx = int(Path(file_name).stem) if Path(file_name).stem.isdigit() else 0
                    
                    payload = dict(
                        frame_index=frame_idx,
                        file_name=file_name,
                        meta_info=pose_estimator.dataset_meta,
                        instance_info=inst_list
                    )
                    
                    save_path = output_dir / f"{Path(file_name).stem}.json"
                    with open(save_path, "w", encoding="utf-8") as f:
                        json.dump(to_py(payload), f, ensure_ascii=False, indent=2)
                    
                    saved_count += 1

        except Exception as e:
            print(f"[Error] {sam_file.name}: {e}")
            continue

    return saved_count

# ============================================================
# 3ï¸âƒ£ ì‹¤í–‰ ë¶€ë¶„ (ìˆ˜ì •ë¨)
# ============================================================
if __name__ == "__main__":
    
    # 1. ë°ì´í„° ê²½ë¡œ ì„¤ì •
    DATA_DIR = Path("/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data")
    
    # --- 2. ê²½ë¡œ ì„¤ì • (Metadata ì‚¬ìš©) ---
    df_path = DATA_DIR / "metadata.csv"
    if not df_path.exists():
        print(f"âŒ Metadata íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {df_path}")
        sys.exit(1)

    df = pd.read_csv(df_path)
    # ì›í•˜ëŠ” ì¸ë±ìŠ¤ì˜ ë¹„ë””ì˜¤ ì„ íƒ (ì˜ˆ: 1ë²ˆ)
    COMMON_PATH = df['common_path'][0] 
    print(f"ğŸ¯ Target Video: {COMMON_PATH}")

    FRAME_DIR = DATA_DIR / "1_FRAME" / COMMON_PATH
    SAM_DIR = DATA_DIR / "8_SAM" / COMMON_PATH

    # [ì¤‘ìš”] Config íŒŒì¼ ê²½ë¡œ
    # ì£¼ì˜: ì´ Config íŒŒì¼ ë‚´ë¶€ì— arch=dict(...) ìˆ˜ì •ì´ ë˜ì–´ ìˆì–´ì•¼ ì—ëŸ¬ê°€ ì•ˆ ë‚©ë‹ˆë‹¤.
    # ë§Œì•½ ì•ˆ ë˜ì‹œë©´ ì´ì „ì— ë§Œë“  'sapiens_0.3b_minimal.py' ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    CONFIG_PATH = Path("/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_sapiens_labeling/configs/sapiens/sapiens_0.3b-210e_coco_wholebody-1024x768.py")
    
    CKPT_PATH = DATA_DIR / "checkpoints/sapiens/pose/sapiens_0.3b_coco_wholebody_best_coco_wholebody_AP_620.pth"

    # 2. ì‹¤í–‰
    print("\n[Job 1] Processing...")
    OUTPUT_DIR = DATA_DIR / "9_KEYPOINTS_V2" / f"{COMMON_PATH}"

    count = extract_keypoints(FRAME_DIR, SAM_DIR, OUTPUT_DIR, str(CONFIG_PATH), str(CKPT_PATH))
    print(f"âœ… ì™„ë£Œ: {count}ê°œ íŒŒì¼ ìƒì„±")