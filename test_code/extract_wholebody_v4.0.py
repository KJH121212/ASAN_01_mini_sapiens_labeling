import sys
import json
import shutil
import cv2
import numpy as np
import pandas as pd
import torch
from pathlib import Path
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader

# --- MMPose ë° MMEngine ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
# Sapiens ëª¨ë¸ì€ MMPose í”„ë ˆì„ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•˜ë¯€ë¡œ ê´€ë ¨ ëª¨ë“ˆì´ í•„ìˆ˜ì…ë‹ˆë‹¤.
try:
    from mmpose.apis import init_model
    from mmpose.utils import register_all_modules
    from mmpose.structures import split_instances, merge_data_samples
    from mmengine.dataset import pseudo_collate
except ImportError:
    print("âŒ MMPose ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. (pip install mmpose mmengine)")
    sys.exit(1)

# --- ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ ì„í¬íŠ¸ ---
# SAM ê²°ê³¼ JSON íŒŒì¼ì—ì„œ BBox(ì‚¬ëŒ ìœ„ì¹˜)ì™€ IDë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
try:
    from functions.extract_bbox_and_id import extract_bbox_and_id
except ImportError:
    # ê²½ë¡œê°€ ì•ˆ ë§ì„ ê²½ìš° ìƒìœ„ í´ë”ë¥¼ ì°¸ì¡°í•˜ë„ë¡ ì„¤ì •
    sys.path.append(str(Path(__file__).resolve().parent.parent))
    from functions.extract_bbox_and_id import extract_bbox_and_id

# --- JSON ì§ë ¬í™” í—¬í¼ í•¨ìˆ˜ ---
# NumPy ë°°ì—´ì´ë‚˜ float32 ê°™ì€ ë¹„-í‘œì¤€ íƒ€ì…ì„ JSON ì €ì¥ ê°€ëŠ¥í•œ ê¸°ë³¸ íƒ€ì…(float, int, list)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
def to_py(obj):
    if isinstance(obj, np.ndarray): return obj.tolist()
    if isinstance(obj, (np.floating,)): return float(obj)
    if isinstance(obj, (np.integer,)): return int(obj)
    if isinstance(obj, dict): return {k: to_py(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple)): return [to_py(v) for v in obj]
    return obj

# ==================================================================================
# 1ï¸âƒ£ Dataset ì •ì˜: SAM BBoxë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì˜ë¼ë‚´ì–´(Crop) ëª¨ë¸ ì…ë ¥ìœ¼ë¡œ ë³€í™˜
# ==================================================================================
class SapiensLiteDataset(Dataset):
    """
    Sapiens ëª¨ë¸ ì¶”ë¡ ì„ ìœ„í•œ ë°ì´í„°ì…‹ í´ë˜ìŠ¤
    - SAMì´ ì°¾ì€ ì‚¬ëŒ ì˜ì—­(BBox)ì„ ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì˜ë¼ëƒ…ë‹ˆë‹¤(Crop).
    - ì˜ë¼ë‚¸ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í¬ê¸°(1024x768)ë¡œ ë³€í™˜(Resize) ë° ì •ê·œí™”(Normalize)í•©ë‹ˆë‹¤.
    """
    def __init__(self, tasks, frame_dir):
        self.frame_dir = Path(frame_dir)
        self.items = []
        self.input_res = (1024, 768)  # Sapiens ëª¨ë¸ì˜ ê³ ì • ì…ë ¥ í•´ìƒë„ (H, W)
        
        # tasks: (SAMê²°ê³¼íŒŒì¼, ì´ë¯¸ì§€íŒŒì¼ëª…, ê°ì²´ë¦¬ìŠ¤íŠ¸) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
        for sam_file, file_name, objects in tasks:
            # íŒŒì¼ëª…ì—ì„œ í”„ë ˆì„ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: 000123.json -> 123)
            f_idx = int(sam_file.stem) if sam_file.stem.isdigit() else 0
            
            for obj in objects:
                # BBoxê°€ ìˆëŠ” ìœ íš¨í•œ ê°ì²´ë§Œ ì²˜ë¦¬
                if obj.get('bbox'):
                    self.items.append({
                        'stem': sam_file.stem,       # íŒŒì¼ ì‹ë³„ì
                        'file_name': file_name,      # ì´ë¯¸ì§€ íŒŒì¼ëª…
                        'frame_idx': f_idx,          # í”„ë ˆì„ ì¸ë±ìŠ¤
                        'obj_id': obj['id'],         # ê°ì²´ ID (Tracking ê²°ê³¼)
                        'bbox': obj['bbox']          # SAMì´ ì°¾ì€ ì›ë³¸ BBox [x1, y1, x2, y2]
                    })
                    
    def __len__(self): 
        return len(self.items)
        
    def __getitem__(self, idx):
        item = self.items[idx]
        
        # 1. ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(str(self.frame_dir / item['file_name']))
        if img is None: return None
        
        x1, y1, x2, y2 = item['bbox']
        h, w = img.shape[:2]
        
        # 2. Crop ì˜ì—­ ê³„ì‚° (Top-Down ë°©ì‹ì˜ í•µì‹¬)
        # ì‚¬ëŒ ì˜ì—­ì„ ë„ˆë¬´ íƒ€ì´íŠ¸í•˜ê²Œ ìë¥´ë©´ í¬ì¦ˆ ì¶”ì •ì´ ì–´ë ¤ìš°ë¯€ë¡œ 1.2ë°° í™•ì¥í•©ë‹ˆë‹¤.
        bw, bh = x2 - x1, y2 - y1       # ë°•ìŠ¤ ë„ˆë¹„, ë†’ì´
        cx, cy = x1 + bw / 2, y1 + bh / 2 # ë°•ìŠ¤ ì¤‘ì‹¬ì 
        
        nw, nh = bw * 1.2, bh * 1.2     # 1.2ë°° í™•ì¥ëœ í¬ê¸°
        
        # ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ì¢Œí‘œ ë³´ì •
        nx1, ny1 = max(0, int(cx - nw / 2)), max(0, int(cy - nh / 2))
        nx2, ny2 = min(w, int(cx + nw / 2)), min(h, int(cy + nh / 2))
        
        # 3. ì´ë¯¸ì§€ ì˜ë¼ë‚´ê¸° (Crop)
        crop = img[ny1:ny2, nx1:nx2].copy()
        
        # 4. ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (Resize)
        # SapiensëŠ” (1024, 768) ì…ë ¥ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤. ë¹„ìœ¨ì´ ë‹¬ë¼ë„ ê°•ì œë¡œ ë§ì¶¥ë‹ˆë‹¤.
        input_img = cv2.resize(crop, (self.input_res[1], self.input_res[0]))
        
        # 5. ì „ì²˜ë¦¬ (HWC -> CHW, ì •ê·œí™”)
        input_img = input_img.transpose(2, 0, 1).astype(np.float32)
        
        # ImageNet í‰ê· /í‘œì¤€í¸ì°¨ ì •ê·œí™” ê°’
        mean = np.array([123.675, 116.28, 103.53]).reshape(3, 1, 1).astype(np.float32)
        std = np.array([58.395, 57.12, 57.375]).reshape(3, 1, 1).astype(np.float32)
        input_img = (input_img - mean) / std
        
        # 6. ê²°ê³¼ ë°˜í™˜ (í…ì„œ, ë©”íƒ€ë°ì´í„°)
        # ë©”íƒ€ë°ì´í„°ëŠ” ë‚˜ì¤‘ì— ëª¨ë¸ ì¶œë ¥ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³µêµ¬í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        return torch.from_numpy(input_img), {
            'stem': item['stem'], 
            'file_name': item['file_name'],
            'frame_idx': item['frame_idx'], 
            'obj_id': item['obj_id'],
            # ì¢Œí‘œ ë³µêµ¬ë¥¼ ìœ„í•œ ì˜¤í”„ì…‹(Crop ì‹œì‘ì )ê³¼ ìŠ¤ì¼€ì¼(Resize ë¹„ìœ¨) ì •ë³´
            'offset': [nx1, ny1], 
            'scale': [crop.shape[1] / self.input_res[1], crop.shape[0] / self.input_res[0]]
        }

# DataLoaderì—ì„œ None ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ê³  ë°°ì¹˜ êµ¬ì„±ì„ ë„ì™€ì£¼ëŠ” í•¨ìˆ˜
def collate_fn(batch):
    batch = [b for b in batch if b is not None]
    if not batch: return None
    # (Input Tensors, Metadata Lists) í˜•íƒœë¡œ ë¶„ë¦¬í•˜ì—¬ ë°˜í™˜
    return torch.stack([b[0] for b in batch]), [b[1] for b in batch]

# ==================================================================================
# 2ï¸âƒ£ ë©”ì¸ ì¶”ë¡  í•¨ìˆ˜: ëª¨ë¸ ë¡œë“œ -> ì¶”ë¡  -> ì¢Œí‘œ ë³µì› -> JSON ì €ì¥
# ==================================================================================
def run_sapiens_lite_inference(frame_dir, sam_dir, output_dir, config_path, ckpt_path, batch_size=25):
    frame_dir, sam_dir, output_dir = Path(frame_dir), Path(sam_dir), Path(output_dir)
    
    # ì¶œë ¥ í´ë” ì´ˆê¸°í™” (ê¸°ì¡´ ê²°ê³¼ ì‚­ì œ í›„ ì¬ìƒì„±)
    if output_dir.exists(): shutil.rmtree(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    register_all_modules() # MMPose ëª¨ë“ˆ ë“±ë¡
    
    # 1. SAM JSON íŒŒì¼ ë¦¬ìŠ¤íŠ¸ì—… ë° ì‘ì—… ëª©ë¡ ìƒì„±
    sam_files = sorted(list(sam_dir.glob("*.json")))
    tasks = []
    print("ğŸ” SAM JSON ìŠ¤ìº” ì¤‘...")
    for sam_file in tqdm(sam_files):
        file_name, objects = extract_bbox_and_id(str(sam_file))
        # í•´ë‹¹ í”„ë ˆì„ ì´ë¯¸ì§€ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•  ë•Œë§Œ ì‘ì—… ëª©ë¡ì— ì¶”ê°€
        if (frame_dir / file_name).exists():
            tasks.append((sam_file, file_name, objects))

    # 2. Sapiens ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš©)
    print("ğŸš€ Sapiens ëª¨ë¸ ë¡œë“œ ì¤‘...")
    model = init_model(str(config_path), str(ckpt_path), device='cuda:0')
    model.eval()

    # 3. ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
    dataset = SapiensLiteDataset(tasks, frame_dir)
    loader = DataLoader(dataset, batch_size=batch_size, num_workers=8, shuffle=False, collate_fn=collate_fn, pin_memory=True)

    print(f"ğŸ”¥ Sapiens-Lite ê³ ì† ì¶”ë¡  ë° Full í¬ë§· ì €ì¥ ì‹œì‘")
    
    # 4. ë°°ì¹˜ ë‹¨ìœ„ ì¶”ë¡  ë°˜ë³µ
    for batch in tqdm(loader, desc="Processing"):
        if batch is None: continue
        inputs, metas = batch
        inputs = inputs.to('cuda', non_blocking=True) # ì…ë ¥ ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™

        with torch.no_grad():
            # [4-1] ëª¨ë¸ Forward
            features = model.backbone(inputs)
            
            # Heatmap Headë¥¼ í†µí•´ ê´€ì ˆë³„ í™•ë¥ ì§€ë„(Heatmap) ìƒì„±
            # ì¶œë ¥ í˜•íƒœ: (Batch, Num_Keypoints, Height/4, Width/4)
            heatmaps = model.head(features)
            if isinstance(heatmaps, (list, tuple)): heatmaps = heatmaps[-1]

            # [4-2] ì¢Œí‘œ ë””ì½”ë”© (Heatmap -> ì¢Œí‘œ)
            # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í”½ì…€ ìœ„ì¹˜(argmax)ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            B, C, H, W = heatmaps.shape
            heatmaps_reshaped = heatmaps.view(B, C, -1)
            max_vals, max_idxs = torch.max(heatmaps_reshaped, dim=2)
            
            # ëª¨ë¸ ì¶œë ¥ì€ ì…ë ¥ í•´ìƒë„ì˜ 1/4 í¬ê¸°ì´ë¯€ë¡œ 4ë¥¼ ê³±í•´ì¤ë‹ˆë‹¤.
            preds_x = (max_idxs % W).float() * 4 
            preds_y = (max_idxs // W).float() * 4

            # [4-3] ë°°ì¹˜ ë‚´ ê° ìƒ˜í”Œ ê²°ê³¼ ì²˜ë¦¬
            for i in range(B):
                meta = metas[i]
                
                # --- ì¢Œí‘œ ì›ë³µ (ì¤‘ìš”) ---
                # ëª¨ë¸ì´ ë³¸ ì¢Œí‘œ(Resizeëœ Crop ì´ë¯¸ì§€ ê¸°ì¤€)ë¥¼ ì›ë³¸ ì´ë¯¸ì§€(Full Frame) ì¢Œí‘œë¡œ ë³€í™˜
                # ê³µì‹: (ëª¨ë¸ì¢Œí‘œ * ìŠ¤ì¼€ì¼) + ì˜¤í”„ì…‹
                final_x = (preds_x[i].cpu().numpy() * meta['scale'][0]) + meta['offset'][0]
                final_y = (preds_y[i].cpu().numpy() * meta['scale'][1]) + meta['offset'][1]
                scores = max_vals[i].cpu().numpy() # ì‹ ë¢°ë„ ì ìˆ˜
                
                # [x, y, score] í˜•íƒœë¡œ ê²°í•©
                keypoints_full = np.stack([final_x, final_y, scores], axis=1).tolist()
                
                # --- ê²°ê³¼ ì €ì¥ìš© ê°ì²´ ìƒì„± ---
                instance_item = {
                    "instance_id": int(meta['obj_id']),
                    "keypoints": keypoints_full,
                    "keypoint_scores": scores.tolist(),
                    # ì°¸ê³ : ì—¬ê¸°ì„œ bboxëŠ” ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ ì— ì‚¬ìš©ëœ 'Crop ì˜ì—­'ì„ ì—­ì‚°í•œ ê°’ì…ë‹ˆë‹¤.
                    # SAM ì›ë³¸ bboxì™€ ë¯¸ì„¸í•˜ê²Œ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì›ë³¸ ìœ ì§€ê°€ í•„ìš”í•˜ë©´ ìˆ˜ì • í•„ìš”)
                    "bbox": [ 
                        meta['offset'][0], meta['offset'][1], 
                        meta['offset'][0] + (1024 * meta['scale'][0]), 
                        meta['offset'][1] + (768 * meta['scale'][1])
                    ]
                }

                # --- JSON íŒŒì¼ ì“°ê¸° ---
                save_path = output_dir / f"{meta['stem']}.json"
                
                # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œí•´ì„œ append(ë‹¤ì¤‘ ê°ì²´ì¸ ê²½ìš°), ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                if save_path.exists():
                    with open(save_path, "r") as f: data_j = json.load(f)
                    data_j['instance_info'].append(instance_item)
                else:
                    data_j = {
                        "frame_index": meta['frame_idx'],
                        "file_name": meta['file_name'],
                        "meta_info": to_py(model.dataset_meta), # Keypoint ì •ì˜ ë“± ëª¨ë¸ ë©”íƒ€ì •ë³´
                        "instance_info": [instance_item]
                    }
                
                with open(save_path, "w", encoding="utf-8") as f:
                    json.dump(data_j, f, ensure_ascii=False, indent=2)

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        torch.cuda.empty_cache()

    return len(list(output_dir.glob("*.json")))

# ==================================================================================
# 3ï¸âƒ£ ì‹¤í–‰ ì§„ì…ì  (Main)
# ==================================================================================
if __name__ == "__main__":
    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    DATA_DIR = Path("/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data")
    
    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ë¡œë“œ ë° ì²˜ë¦¬í•  ë¹„ë””ì˜¤ ê²½ë¡œ ì„ íƒ
    df = pd.read_csv(DATA_DIR / "metadata.csv")
    COMMON_PATH = df['common_path'][1] # ì˜ˆì‹œë¡œ ë‘ ë²ˆì§¸ ë¹„ë””ì˜¤ ì„ íƒ
    
    # ì…ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    FRAME_DIR = DATA_DIR / "1_FRAME" / COMMON_PATH       # ì›ë³¸ ì´ë¯¸ì§€ í´ë”
    SAM_DIR = DATA_DIR / "8_SAM" / COMMON_PATH           # SAM ê²°ê³¼(bbox) í´ë”
    OUTPUT_DIR = DATA_DIR / "9_KEYPOINTS_V2" / COMMON_PATH # ìµœì¢… Pose ê²°ê³¼ ì €ì¥ í´ë”
    
    # ëª¨ë¸ ì„¤ì • íŒŒì¼ ë° ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
    CONFIG = "/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_mini_sapiens_labeling/configs/sapiens/sapiens_0.3b-210e_coco_wholebody-1024x768.py"
    CKPT = DATA_DIR / "checkpoints/sapiens/pose/sapiens_0.3b_coco_wholebody_best_coco_wholebody_AP_620.pth"

    # ì¶”ë¡  ì‹¤í–‰ (Batch Size ì¡°ì ˆ ê°€ëŠ¥)
    count = run_sapiens_lite_inference(FRAME_DIR, SAM_DIR, OUTPUT_DIR, CONFIG, CKPT, batch_size=30)
    print(f"âœ… ì™„ë£Œ: {count}ê°œ JSON ìƒì„±")